---
title: "Coursera Data Analysis"
author: "Eirlys Vo"
date: "2024-08-28"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::clean_cache()
```

## Objective

The goal of this project is to perform a comprehensive analysis of a dataset related to Coursera courses. I explored the dataset to understand the data structure and performed necessary data cleansing. Then, I created visualizations to see insights for online studying trends and user engagement.

## Data Collection

The data is provided on Kaggle, which can be viewed [here.](https://www.kaggle.com/datasets/elvinrustam/coursera-dataset)

There are two datasets which are cleaned and uncleaned. For this project, I will only use the uncleaned version since our aim includes data cleansing. The dataset includes various columns which are basic information about a course. I will use `URL` link as our main unique index, which I will also clean on this in the **Project Workflow** section.

Further dataset description can be read [here.](https://www.kaggle.com/datasets/elvinrustam/coursera-dataset)

First, I will read the dataset using `read.csv` function, save as `unclean_data`, and see an overview of the dataset:

```{r}
orig_df <- read.csv("CourseraDataset-Unclean.csv")
summary(orig_df)
colnames(orig_df)
```

## Libraries and Tools

I will set up necessary libraries that can help me clean and visualize data in further steps:

```{r}
library(tidyverse)
library(zoo)
library(textcat)
sessionInfo()
```

## Project Workflow

### 1. Set columns name

The dataset has some columns' names which I find them hard to use throughout the workflow. Therefore, I would rather change them into easily accessible names. I will use the `rename` function to apply new columns' names:

```{r}
orig_df <- rename(orig_df, crs_title = "Course.Title")
orig_df <- rename(orig_df, will_learn = "What.you.will.learn")
orig_df <- rename(orig_df, offered = "Offered.By")
orig_df <- rename(orig_df, URL = "Course.Url")
orig_df <- rename(orig_df, skill = "Skill.gain")

data_types <- sapply(orig_df, typeof)
results <- paste(names(orig_df), ":", data_types, collapse = ", ")
cat(results,'\n')
```

We want to use function `head()` to see the format of data in every column:

```{r}
head(orig_df)
```

### 2. Cleansing N/A values for Rating col

In cleansing process, I first want to see the amount of N/A values in every column:

```{r}
colSums(is.na(orig_df))
```

There are about 1500 `N/A` values for column `Rating`. The `Rating` column has format of `double` so to be easy, we can fill `N/A` with 0.

In case we need to clean any sudden `N/A` in the future (if having additional column), it would be better to create a custom function to help us handle this. The function will need inputs of a data frame, column's name need to be cleansed, and the replaced value for it.

We use `mutate()` to easily access the data frame and its columns. Then, we use `sym()` function to converts the column name from a string to a symbol since our input `colname` of the function is a string and `mutate()` can't handle string. We need `!!` before it to unquote the `sym()` function.

Then, we have the `ifelse` to check a value is `N/A`:

```{r}
clean_NA_func <- function(input_df, colname, replace_value) {
  input_df <- input_df %>% mutate(
    !!sym(colname) := ifelse(
      is.na(!!sym(colname)), replace_value, !!sym(colname)
    )
  )
  return(input_df)
}
```

We now apply this function to clean the `Rating` column and check again:

```{r}
orig_df <- clean_NA_func(orig_df, "Rating", 0)
colSums(is.na(orig_df))
```

### 3. Cleansing empty values for Level column

There are some entries that are not identified as `N/A` but empty. We want to build a function that helps fill those empty entries with desired values. The logic behind this function is similar to the `clean_NA_func`, but we replace the condition checking `is.na` with `== ""`.

```{r}
colSums(orig_df == "")
clean_empty_func <- function(input_df, colname, replace_value) {
  input_df <- input_df %>% mutate(
    !!sym(colname) := ifelse(
      !!sym(colname) == "", replace_value, !!sym(colname)
    )
  )
}
```

There are number of columns with empty entries. Depending on each column data structure, we fill the empty with different values.

```{r}
columns_to_clean = c('Level','Duration','Schedule','will_learn','skill','Modules','Instructor')

for (col in columns_to_clean) {
  orig_df <- clean_empty_func(orig_df, col, 'No information')
}

colSums(orig_df=="")
```

For `Review` column specifically, since there is `reviews` in the entries, we will remove this word (using `str_replace_all`), fill the empty ones with 0, and then convert the data back to `double` type for further analysis purpose.

```{r}
orig_df$Review <- str_replace_all(orig_df$Review, fixed(" reviews"), "")
orig_df <- clean_empty_func(orig_df, 'Review', '0')
orig_df$Review <- as.double(orig_df$Review)
```

### 4. Cleaning duplicated URL link

As mentioned in **Objective**, we use URL link as our main index, so we need to clean the duplicated link. Also, there are rows with same link but different keywords so we want to append the keywords together. The logic behind this function is to use the `while` loop to continuously track the existing of duplication. We want to save the indices of duplicated URL rows, pasting the keywords of larger indices rows to the minimum one and then remove those bigger indices rows.

```{r}

sum(duplicated(orig_df$URL))

clean_dup_func <- function(input_df, col_dup, col_append) {
  while (sum(duplicated(input_df[, col_dup])) >= 1) {
    
    dup_df <- input_df[which(duplicated(input_df[, col_dup])), ] # get df of duplicated rows of URL
    link_1st_row <- as.character(dup_df[1, col_dup])
    row_indices <- as.numeric(which(input_df[, col_dup] == link_1st_row)) # get rows having same links
    row_indices_without_min <- row_indices[-which.min(row_indices)]

    for (i in row_indices_without_min) {
      input_df[min(row_indices), col_append] <- paste(
        input_df[min(row_indices), col_append], input_df[i, col_append],
        sep = ", "
      )
    }
    
    input_df <- input_df[-row_indices_without_min, ]
    
  }

  return(input_df)
}

orig_df <- clean_dup_func(orig_df, "URL", "Keyword")
summary(orig_df)
```

### 5. Cleaning ***Social Sciences*** duplication in Keyword column

After we perform the fourth cleaning, there seems to be duplicated `Social Sciences` keyword and we don't want that. At this step, we don't build a custom function here. Instead, we directly replace any row having more than 1 `Social Sciences` keyword with single term. We perform that with functions `str_count` for counting purpose and `str_replace_all` for replacing purpose.

```{r}
orig_df$Keyword <- ifelse(
  str_count(orig_df$Keyword, fixed("Social Sciences")) > 1, str_replace_all(
    orig_df$Keyword, fixed("Social Sciences, Social Sciences"), "Social Sciences"
  ), orig_df$Keyword
)

unique(
  (orig_df %>% mutate(
    count_ss = str_count(orig_df$Keyword, fixed("Social Sciences"))
  )
  )$count_ss
)
```

After performing replacement, we can see that now every row only has 0 or 1 keyword `Social Sciences` and this is desirable.

### 6. Cleaning specific signs ***[,],'***

When viewing the data set, there are columns skill, Modules, Instructor, offered having specific signs in their values. We want to get rid of these for consistent data purpose. Since there are different signs, we want to build a custom function for different inputs purpose. The logic behind this custom function is similar to the others created above, but we have placeholder for `sign2` and `sign3` inputs since we are not sure how many signs we will have and use function `gsub` for matching and replacement.

```{r}
head(orig_df)

clean_sign_func <- function(input_df, colname, sign1, sign2 = "", sign3 = "") {
  input_df[, colname] <- sapply(input_df[, colname], function(x) {
    x <- gsub(paste0(fixed(sign1), "|", fixed(sign2), "|", fixed(sign3)), "", x)
  })
  return(input_df)
}

# Apply function
orig_df <- clean_sign_func(orig_df, "skill", "\\[", "\\]", "'")
orig_df <- clean_sign_func(orig_df, "Modules", "\\[", "\\]", "'")
orig_df <- clean_sign_func(orig_df, "Instructor", "\\[", "\\]", "'")
orig_df <- clean_sign_func(orig_df, "offered", "\\[", "\\]", "'")
```

After removing signs, there are empty entries so we will use `clean_empty_func`:

```{r}

```

### 7. Cleaning ***Duration*** column

Having a look at `Duration` column, we see there is inconsistency how data is structure. Therefore, we will change these into single unit `hour`.

```{r}
orig_df %>% head(20) %>% select(Duration)
```

Have a look at unique values for `Duration`:

```{r}
unique(orig_df$Duration)
```

We can see that there are empty ones, `approx` or `approximately`, `hours`, `minutes`, `week`, and `month`. There is one entry with a full sentence, which is the longest entry. There is entry with `one hour` which does not use digit but letters. Steps to clean include:

-   Replace the longest one with a correct one with function `which.max`
-   Replace the letters but not digit with a correct one with `which` to find the row index

## Improvements to make
